%----------------------------------------------------------------------------
\chapter{Elméleti megalapozás}
%----------------------------------------------------------------------------

\section {Numerikus módszerek}

Mit is nevezünk tulajdonképpen numerikus módszereknek vagy numerikus analízisnek? Azt a tudományt, amely az analitikus problémák vagy feladatok megközelítésével és a megközelítő megoldások keresésével foglalkozik. Fontos tudni, hogy ezek a módszerek és technikák egyre jobban fejlődtek és fejlődnek napjainkban is, de a pontos, analitikus megoldást soha nem érik el (ez a gyakorlatban lehetetlen). Tehát a numerikus módszerek úgy próbálják a megoldást megközelíteni, hogy a közelítő értékek egy adott, elfogadható hibahatáron belül maradjanak.

A módszerek fontossága abban rejlik, hogy bizonyos esetekben a probléma analitikus megoldása nagyon komplex, időigényes vagy szinte lehetetlen lehet, ezekben az esetekben próbáljuk a megoldást megközelíteni valamilyen numerikus módszer segítségével. Napjainkban ezeket a számításokat már nem papíron és kézzel végezzük, hanem számítógépen \cite{DiffEgyenletesKonyv}, \cite{DavidLoganBook}. A továbbiakban nézzük meg a módszerek fejlődését és pár módszert részletesebben is, amelyeket differenciálegyenletek megoldásainak megközelítésére használnak.

\section {Euler-féle (törtvonal) módszer}

Az Euler-módszer a legegyszerűbb numerikus eljárás a kezdetiérték típusú feladatok, differenciálegyenletek megoldására. A módszer lényege, hogy adott egy függvény és ismert a függvény értéke is a kezdeti időpillanatban ($t_{0}$). Ezen előzetes ismeretek alapján pontról-pontra számítjuk ki a megoldást ($y_{i}$ ordináta kiszámításához egy előzőleg már kiszámított $y_{i-1}$ ordinátát használunk) egy adott \newline [$t_{0}$, $t_{f}$] intervallumon, ahol a függvény értéke mindig egy konstanssal növekszik ($ h $). Az eljárás végrehajtása után diszkrét pontokat kapunk, amelyeket ha összekötünk egy törvonalat eredményez, ezért nevezik ezt a módszert „törtvonal” módszernek is \cite{KupanPalJegyzet}, \cite{DiffEgyenletesKonyv}, \cite{Diplomadolgozat}.

A továbbiakban vizsgáljuk meg a következő differenciálegyenletet és a hozzá tartozó kezdeti feltétel (kezdetiérték probléma), amelyet szeretnénk megoldani Euler módszerrel:
\begin{align}
	\begin{cases}
		y'(t) = f(t,y(t)) \\
		y(t_{0}) = y_{0}
	\end{cases}
	,t\in[t_{0}, t_{f}]
\end{align}
A megoldás első lépése, hogy az egyenlet mindkét oldalát integráljuk:
\begin{align}
	\int_{t_{0}}^{i} \dfrac{dy(t)}{dt} dt = \int_{t_{0}}^{i} f(t,y(t)) dt
\end{align}
Ezután alkalmazzuk a Newton-Leibniz formulát:
\begin{align}
	y(i)-y(t_{0}) = \int_{t_{0}}^{i} f(t,y(t)) dt
\end{align}
A fenti egyenlet átrendezése után a következő összefüggéshez jutunk:
\begin{align} \label{atrendezett}
	y(i) = y(t_{0}) + \int_{t_{0}}^{i} f(t,y(t)) dt
\end{align}
A kifejezés jobb oldalán álló integrált bontsuk fel véges $\Delta t$ összegekre ($\Delta t \to 0$ esetben visszakapjuk a \ref{atrendezett} egyenletet):
\begin{align}
	y(i) = y(t_{0}) + \sum_{t=t_{0}}^{i} f(t,y(t)) \Delta t
\end{align}
Az első tag kiszámításának képlete a fenti egyenlet és a kezdeti feltételek alapján:
\begin{align}
	y(t_{0}+ \Delta t) = y_{0} + f(t_{0},y(t_{0})) \Delta t
\end{align}
Ezek alapján felírható az Euler módszer általános képlete, amellyel egy következő tagot számítunk ki:
\begin{align} \label{eq:altalanosKeplet}
	y_{i+1} = y_{i} + hf(t_{i},y_{i}),
\end{align}
ahol $h = \dfrac{t_{t}-t_{0}}{n}$ lépésköz és $n$ egy rögzített természetes szám.
\newpage
A módszer alkalmasságát, használhatóságát differenciálegyenletek megoldására konvergenciája biztosítja. Ahhoz, hogy az \textbf{Euler módszer konvergenciáját} beláthassuk nézzük meg a következő tulajdonságokat a \cite{DiffEgyenletesKonyv} könyvben leírtak alapján:
\begin{theorem}
	Euler módszer tulajdonságai:
	\begin{itemize}
		\item[(i)] Ha létezik megoldás ($ f \in $ Lip($ y $)), akkor az Euler módszer stabil azaz érvényes
		\begin{align*}
			|e_{i}| \leq e^{L_{f}} \left(|e_{0}| + \displaystyle\sum_{k=0}^{i-1} |g_{k}|h \right),
		\end{align*}
		ahol $ e_{i} = e(x_{i},h) = y(x_{i})-y_{i} $ a módszer globális hibája, $ g_{i} = g(x_{i},h) = \frac{y(x_{i+1})-y(x_{i})}{h} - f(x_{i},y(x_{i})) $ a módszer lokális hibája, $ L_{f} $ pedig az $ f $ Lipschitz-állandója.
		\item[(ii)] Ha $ y \in C^{2} $, akkor az Euler módszer konzisztens és $ g_{i} $ lokális hibára igaz a következő:
		\begin{align*}
			|g_{i}| \leq \frac{h}{2}M_{2},
		\end{align*}
		ahol $ M_{2} = \displaystyle\max_{[0,1]} |y''(x)|$.
		\item[(iii)] „stabilitás + konzisztencia = konvergencia”. Ha $ e_{0} = 0 $ és $ y \in C^{2} $, akkor a $ [0,1] $ intervallumon az Euler módszer konvergens lesz. Konvergencia rendje egybeesik a konzisztencia rendjével:
		\begin{align*}
			|e_{i}| = |y(x_{i})-y_{i}| \leq e^{L_{f}}\frac{h}{2}M_{2} = Mh.
		\end{align*}
	\end{itemize}
\end{theorem}
A fenti tulajdonságok levezetései és bizonyításai megtalálhatóak a \cite{DiffEgyenletesKonyv} könyvben. \newline

Végül megemlíteném, hogy az Euler módszer nagy hátránya, hogy nem túl pontos, az \eqref{altalanosKeplet} egyenletből adódóan a módszer \textbf{hibarendje} $ n $ lépés után lineáris, tehát \textbf{$\mathcal{O}(h)$} nagyságrendű. További hátrányai: nagyon kis $ h $ lépésközt alkalmazva nagyon megnőhet a számítási idő és az erőforrások kihasználtsága, valamint kerekítési hibák is felgyűlhetnek az egymás utáni lépések során.
\newpage

\section {Runge-Kutta4 módszer}

A Runge-Kutta4 módszer egy javított vagy továbbfejlesztett Euler módszer, ami egy kezdetiérték-probléma negyedrendű közelítő megoldását adja. Ez azt jelenti, hogy a lépésköz zsugorításakor annak negyedik hatványára zsugorodik a hibára adott felső becslés \cite{KupanPalJegyzet}, \cite{DiffEgyenletesKonyv}, \cite{Diplomadolgozat}, \cite{RungeKuttaFormula}.

Az Euler módszerhez képest annyit változtatunk a képleten, hogy az eredeti képlettel nem teszünk meg egy teljes lépést, hanem több részre osztjuk ezt is és a kapott pontokban újraszámítjuk az $f$ értékét:
\begin{align} \label{eq:RungeKutta}
	y_{i+1} &= y_{i} + h\sum_{j=1}^{m}b_{j}k_{j},
\end{align}
ahol $b_{j} $ konstans súlyértéket és $m$ a módszer rendjét jelenti, amelyre $b_{1} + b_{2}+ ... +b_{m} = 1$, emellett\\
\begin{align} \label{eq:kErtek}
	k_{j} &= f\left(t_{i}+hc_{j}, y_{i}+h \sum_{l=1}^{j-1}a_{jl}k_{l}\right),
\end{align}
ahol $c_{j} $ és $a_{jl}$ szintén konstans súlyértékek, ezeket az értékeket egy úgynevezett „Butcher” táblában szokták tárolni, amely a következőképpen néz ki $ m = 4 $ esetén: 
\[
\renewcommand\arraystretch{1.2}
\begin{array}
{c|cccc}
c_{1} = 0\\
c_{2} = \sfrac{1}{2} & a_{21} = \sfrac{1}{2}\\
c_{3} = \sfrac{1}{2} & a_{31} = 0 & a_{32} = \sfrac{1}{2} \\
c_{4} = 1 & a_{41} = 0 & a_{42} = 0 & a_{43} = 1\\
\hline
& b_{1} = \sfrac{1}{6} & b_{2} = \sfrac{1}{3} & b_{3} = \sfrac{1}{3} & b_{4} = \sfrac{1}{6} 
\end{array}
\]
Ha az \eqref{RungeKutta} és \eqref{kErtek} egyenletekbe az $m = 1$ és $b_{1} = 1$ paramétereket helyettesítjük, akkor pont az Euler módszer alapegyenletét kapjuk:
\begin{align*}
	k_{1} &= f(t_{i},y_{i}), \\
	y_{i+1} &= y_{i} + hk_{1}.
\end{align*}
Ezek alapján felírhatjuk a Runge-Kutta4 általános képletét ($m = 4$ esetben):
\begin{align}
	y_{i+1} = y_{i} + \dfrac{h}{6}(k_{1}+2k_{2}+2k_{3}+k_{4}),
\end{align}
ahol
\begin{align*}
	k_{1} &= f(t_{i},y_{i}), \\
	k_{2} &= f(t_{i}+\dfrac{1}{2}h,y_{i}+\dfrac{1}{2}hk_{1}), \\
	k_{3} &= f(t_{i}+\dfrac{1}{2}h,y_{i}+\dfrac{1}{2}hk_{2}), \\
	k_{4} &= f(t_{i}+h,y_{i}+hk_{3}) \\
\end{align*}

Ezután vizsgáljuk meg a \textbf{Runge-Kutta módszer konvergenciáját}, amelyet hasonlóan fogunk belátni, mint az Euler módszerét:
\begin{theorem}\label{rugeKuttaTetel}
	Legyen $ f \in $ Lip($ y $), $ L_{f} $ Lipschitz-állandóval, akkor a Runge-Kutta módszer $ stabil $: érvényes
	\begin{align*}
		|e_{i}| \leq e^{L_{\Phi}} \left(|e_{0}| + \displaystyle\sum_{k=0}^{i-1} |g_{k}|h \right),
	\end{align*}
	ahol
	\begin{align*}
		L_{\Phi} = L_{f}\left(\displaystyle\sum_{j=1}^{s} |c_{j}|+Q_{s-1}(hL_{f})\right),
	\end{align*}
	és $ Q_{s-1}(hL_{f}) $ tag a $ hL_{f} $-nek $ (s-1) $-edfokú polinomja, amely eleget tesz $ Q_{s-1}(hL_{f}) = O(hL_{f})$-nek.
\end{theorem}
\begin{conclusion}
	Ha $ y_{0} = y(0) $, $ f \in C^{1} \{[0,1] \times \mathbb{R}\}$ és $ \displaystyle\sum_{j=1}^{s} c_{j} = 1 $, akkor az \eqref{RungeKutta}-as képlettel felírt Runge-Kutta módszer konvergens.
\end{conclusion}
A \ref{rugeKuttaTetel}-es tétel bizonyítása, levezetése szintén megtalálható a \cite{DiffEgyenletesKonyv} könyvben. \newline

Összességében a Runge-Kutta4 módszer sokkal pontosabb eredményeket ad, mint az Euler módszer, mivel a \textbf{hibarendje $\mathcal{O}(h^{4})$}. Emellett hátránya az lehet, hogy túl kicsi lépésköz és nagy intervallum esetén időigényesebb, mint az Euler módszer, de összességében sokkal hatékonyabb, ezért nagyon elterjedt numerikus módszer a számítástechnikában. Későbbiekben ebből a módszerből fejlődtek ki a jóval komplexebb, de hatékonyabb adaptív módszerek, ahol a lényeges újítás az lesz, hogy a lépésköz nem állandó, hanem minden iterációban újraszámítódik.

\section {Dormand-Prince (DoPri45) módszer}

A Dormand-Prince módszer egy egylépéses adaptív Runge-Kutta eljárás, ami azt jelenti, hogy minden lépésben kiszámítja a becsült helyi kerekítési hibát. Ennek megvalósítására két módszert alkalmaz egy lépésben, egy 4-ed és egy 5-öd rendű Runge-Kuttát. A módszer fontos tulajdonsága, hogy váltakozó lépésközű, mindig úgy választja meg a lépésközt, hogy a hiba a negyedrendű módszer hibája legyen \cite{RungeKuttaFormula}. \newline \newline
Egy lépés kiszámításának menete a következőképpen néz ki \cite{DoPri45}:
\begin{align}
	y_{i+1} = y_{i} + b_{1}k_{1} + b_{3}k_{3} + b_{4}k_{4} + b_{5}k_{5} + b_{6}k_{6},
\end{align}
ahol
\begin{align*}
	k_{1} &= hf(t_{i}+c_{1}h,y_{i}+a_{11}), \\
	k_{2} &= hf(t_{i}+c_{2}h,y_{i}+a_{21}k_{1}), \\
	k_{3} &= hf(t_{i}+c_{3}h,y_{i}+a_{31}k_{1}+a_{32}k_{2}), \\
	k_{4} &= hf(t_{i}+c_{4}h,y_{i}+a_{41}k_{1}+a_{42}k_{2}+a_{43}k_{3}), \\
	k_{5} &= hf(t_{i}+c_{5}h,y_{i}+a_{51}k_{1}+a_{52}k_{2}+a_{53}k_{3}+a_{54}k_{4}), \\
	k_{6} &= hf(t_{i}+c_{6}h,y_{i}+a_{61}k_{1}+a_{62}k_{2}+a_{63}k_{3}+a_{64}k_{4}+a_{65}k_{5}), \\
	k_{7} &= hf(t_{i}+c_{7}h,y_{i}+a_{71}k_{1}+a_{73}k_{3}+a_{74}k_{4}+a_{75}k_{5}+a_{76}k_{6}) \\
\end{align*}
Ez volt a negyedrendű Runge-Kutta, amellyel kiszámítottuk a következő lépést, $ y_{i+1} $-t $ y_{i} $ függvényében. Láthatjuk, hogy ebben az esetben nem használtuk a $ k_{2} $ paramétert, mivel azt a $ k_{3} $ számításánál hsználjuk fel és így tovább. Az algoritmus következő lépésében egy ötödrendű Runge-Kutta alkalmazásával kiszámítjuk a becsült helyi kerekítési hibát:
\begin{align}
	error = \left|e_{1}k_{1} + e_{3}k_{3} + e_{4}k_{4} + e_{5}k_{5} + e_{6}k_{6} + e_{7}k_{7}\right|
\end{align}
Miután megkaptuk ebben a lépésben a hiba nagyságát, ennek segítségével kiszámítjuk az optimális lépés hosszát:
\begin{align*}
	s &= \left( \dfrac{\epsilon h}{2|error|} \right)^ {\dfrac{1}{5}}, \\
	h_{opt} &= sh,
\end{align*}
ahol \textit{h} az előző lépés hosszát, $\epsilon$ pedig a toleranciát jelöli, ez az érték alapértelmezetten $ \epsilon = 10^{-6} $ szokott lenni, de általában minden rendszerben konfigurálható.

Fontos megemlíteni, hogy az optimális lépés hosszának kiszámítására léteznek más módszerek is. Amennyiben javítani szeretnénk az algoritmus pontosságán és hatékonyságán érdemes más módszereket is kipróbálni vagy tesztelgetni. Léteznek heurisztikus paraméterek, amelyeket tapasztalati úton ismertek meg a módszerrel foglalkozók, amelyeket szintén felhasználhatunk az optimális lépéshossz meghatározásánál.

A fenti egyenletekben használt együtthatókat ($ a_{ij} $, $ b_{i} $, $ c_{i} $, $ e_{i} $) egy táblában szokták tárolni, melynek neve „Butcher tábla”, hasonlóan a Runge-Kutta módszerben használatos táblához \cite{RungeKuttaFormula}:

\[
\renewcommand\arraystretch{1.2}
\begin{array}
{c|ccccc}
c_{1} \\
c_{2} & a_{21}\\
c_{3} & a_{31} & a_{32} \\
\vdots & \vdots & & \ddots \\
c_{i} & a_{i1} & a_{i2} & \cdots & a_{i,i-1}\\
\hline
& b_{1} & b_{2} & \cdots & b_{i-1} & b_{i} \\
& e_{1} & e_{2} & \cdots & e_{i-1} & e_{i}
\end{array}
\]
A Dormand-Prince módszerben használt konkrét értékek a következők:
\[
\renewcommand\arraystretch{1.2}
\begin{array}
{c|ccccccc}
0\\
\sfrac{1}{5} & \sfrac{1}{5}\\
\sfrac{3}{10} & \sfrac{3}{40} & \sfrac{9}{40} \\
\sfrac{4}{5} & \sfrac{44}{45} & \sfrac{-56}{15} & \sfrac{32}{9}\\
\sfrac{8}{9} & \sfrac{19372}{6561} & \sfrac{-25360}{2187} & \sfrac{64448}{6561} & \sfrac{-212}{729}\\
1 & \sfrac{9017}{3168} & \sfrac{-355}{33} & \sfrac{46732}{5247} & \sfrac{49}{176} & \sfrac{-5103}{18656}\\
1 & \sfrac{35}{384} & 0 & \sfrac{500}{1113} & \sfrac{125}{192} & \sfrac{-2187}{6784} & \sfrac{11}{84}\\
\hline
& \sfrac{35}{384} & 0 & \sfrac{500}{1113} & \sfrac{125}{192} & \sfrac{-2187}{6784} & \sfrac{11}{84} & 0\\
& \sfrac{5179}{57600} & 0 & \sfrac{7571}{16695} & \sfrac{393}{640} & \sfrac{-92097}{339200} & \sfrac{187}{2100} & \sfrac{1}{40}
\end{array}
\]

Összességében a Dormand-Prince módszer egy hatékony adaptív numerikus eljárás kezdetiérték-probléma típusú differenciálegyenletek megoldására, melynek \textbf{hibarendje} lépésenként \textbf{$\mathcal{O}(h^{5})$}, összességében pedig \textbf{ $\mathcal{O}(h^{4})$}. Hatékonyságát bizonyítja, hogy napjainkban a Matlab, GNU Octave és számos más programozási nyelv, programrendszer is alapértelmezett differenciálegyenlet megoldó algoritmusként a Dormand-Prince numerikus módszert alkalmazzák.

\section {Dormand-Prince módszert tartalmazó szoftverek, könyvtárak} \label{fejezet1_5}

Ahogy az előzőekben is említettem a Dormand-Prince módszer nagy pontosságának és hatékonyságának köszönhetően széles körben alkalmazott kezdetiérték-feladatok megoldására. Számos szoftverben és technológiában megtalálható az implementációja, mint alapértelmezett differenciálegyenlet megoldó. Az alábbi táblázatban összefoglaltam egy pár ismertebb szovtvert, könytárat, melyek közül néhányat ki is próbáltam (ezeket a későbbiekben részletesen megviszgáljuk a \ref{fejezet3}. fejezetben).
\begin{table}[h!]
	\centering
	\begin{tabular}{ | l | c | c | c |}
		\hline 
		\textbf{Szoftver} & \textbf{Ár (2017)} & \textbf{Nyílt forráskód} & \textbf{Platform}\\
		\hline
		Matlab Standard & 2000 \euro & nem & Win., Lin., Mac\\
		\hline
		Matlab Education & 500 \euro & nem & Win., Lin., Mac\\
		\hline
		Matlab Home & 119 \euro & nem & Win., Lin., Mac\\ 
		\hline
		Matlab Student & 69 \euro & nem & Win., Lin., Mac\\
		\hline
		Maple Personal Edition & 299 US\$ & nem & Win., Lin., Mac\\
		\hline
		Maple Student Edition & 124 US\$ & nem & Win., Lin., Mac\\
		\hline
		GNU Octave & ingyenes & igen & Win., Lin., Mac\\
		\hline
		FreeFem++ & ingyenes & igen & Win., Lin., Mac\\
		\hline
		Freemat & ingyenes & igen & Win., Lin., Mac\\
		\hline
		Scilab & ingyenes & igen & Win., Lin., Mac\\
		\hline
		Boost - Odeint & ingyenes & igen & Win., Lin., Mac\\
		\hline
		GeoGebra & ? & ? & Win., Lin., Mac\\
		\hline
	\end{tabular}
	\caption{Szoftverek diff. egyenletek megoldására.}
\end{table}

A fenti táblázatban felsorolt szoftverek közül néhánynak hátrányai is vannak, amint azt láthatjuk. \textbf{Problémát jelenthet} egy szoftver esetében ha \textbf{nem ingyenes}, egyes esetekben a licensz megvásárlása költséges lehet, mint a Matlab vagy Maple. Emellett szintén probléma lehet az is, ha \textbf{nem nyílt forráskódú} vagy \textbf{nem platformfüggetlen}.

Szerencsére vannak jó alternatívák is, amelyek már ingyenesek és nyílt a forráskódjuk is. A Matlab vagy Maple esetében a legjobb alternatíva a GNU Octave programcsomag, amely teljesen ingyenes. Vannak azonban olyan szoftverek is, melynek bizonyos részei ingyenes, mások pedig nem (pl. GeoGebra). Ha C++ nyelvben jártasak vagyunk és szeretnénk egy hatékony és gyors könyvtárat beépíteni a programunkba, akkor érdemes a Boost könyvtárat használni az STL helyett, amiben az Odeint nevezetű modulban szintén megtalálható az előre megírt és optimizált Dormand-Prince algoritmus.
\newpage
Összegzésképpen elmondhatom, hogy érdemes ezeket a szoftvereket kipróbálni és használni. Azonban bennem felmerült a kérdés, hogy tudunk e mi is hasonlóan gyors és hatékony Dormand-Prince módszert alkalmazó szoftvert írni? És ha tudunk megéri e egyáltalán? Kérdéseimre a válaszokat megtudjuk dolgozatom további fejezeteiből.